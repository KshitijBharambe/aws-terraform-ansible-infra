#!/bin/bash
# Log Backup Script
# Generated by Ansible for {{ ansible_hostname }}
# Environment: {{ ansible_environment }}
# Generated: {{ ansible_date_time }}

# Load configuration
source /etc/backup/backup-config.sh

# Function to log messages
log_message() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" >> "$LOG_FILE"
}

# Function to send email notification
send_notification() {
    local subject="$1"
    local message="$2"
    
    if [ "$EMAIL_ENABLED" = "true" ]; then
        echo "$message" | mail -s "$subject" -r "$EMAIL_FROM" "$EMAIL_TO"
        log_message "Notification sent: $subject"
    fi
}

# Function to create backup directory
create_backup_dir() {
    local backup_path="$1"
    mkdir -p "$backup_path"
    chmod 750 "$backup_path"
    chown $BACKUP_USER:$BACKUP_GROUP "$backup_path"
}

# Function to backup log files
backup_logs() {
    local timestamp=$(date +%Y%m%d_%H%M%S)
    local backup_name="logs_backup_${timestamp}"
    local backup_file="${LOG_BACKUP_DIR}/${backup_name}.tar.gz"
    
    log_message "Starting log backup: $backup_name"
    
    create_backup_dir "$LOG_BACKUP_DIR"
    
    local temp_dir="${LOG_BACKUP_DIR}/${backup_name}"
    mkdir -p "$temp_dir"
    
    local found_logs=false
    
    # Backup logs from specified directories
    for log_dir in "${LOG_DIRS[@]}"; do
        if [ -d "$log_dir" ]; then
            log_message "Processing log directory: $log_dir"
            
            # Create directory structure in backup
            local dest_dir="$temp_dir$(echo "$log_dir" | sed 's/\//_/g')"
            mkdir -p "$dest_dir"
            
            # Copy log files (excluding compressed archives)
            find "$log_dir" -name "*.log" -type f -exec cp {} "$dest_dir/" \;
            find "$log_dir" -name "*.log.*" -type f -exec cp {} "$dest_dir/" \;
            
            # Check if any logs were copied
            if [ "$(ls -A "$dest_dir" 2>/dev/null)" ]; then
                found_logs=true
                log_message "Logs copied from: $log_dir"
            else
                rmdir "$dest_dir" 2>/dev/null
            fi
        else
            log_message "Log directory not found: $log_dir"
        fi
    done
    
    if [ "$found_logs" = true ]; then
        # Create archive
        tar -czf "$backup_file" -C "$LOG_BACKUP_DIR" "$backup_name"
        rm -rf "$temp_dir"
        
        chmod 640 "$backup_file"
        chown $BACKUP_USER:$BACKUP_GROUP "$backup_file"
        
        log_message "Log backup completed: $backup_file"
        echo "$backup_file"
        return 0
    else
        log_message "No log files found for backup"
        rm -rf "$temp_dir"
        return 1
    fi
}

# Function to backup application-specific logs
backup_app_logs() {
    local timestamp=$(date +%Y%m%d_%H%M%S)
    local backup_name="app_logs_backup_${timestamp}"
    local backup_file="${LOG_BACKUP_DIR}/${backup_name}.tar.gz"
    
    log_message "Starting application log backup: $backup_name"
    
    local temp_dir="${LOG_BACKUP_DIR}/${backup_name}"
    mkdir -p "$temp_dir"
    
    local found_logs=false
    
    # Common application log locations
    local app_log_dirs=(
        "${APP_DIR}/logs"
        "${APP_DIR}/storage/logs"
        "${APP_DIR}/var/log"
        "/var/log/application"
        "/opt/application/logs"
    )
    
    for app_log_dir in "${app_log_dirs[@]}"; do
        if [ -d "$app_log_dir" ]; then
            log_message "Processing application log directory: $app_log_dir"
            
            local dest_dir="$temp_dir/app_logs_$(basename "$app_log_dir")"
            mkdir -p "$dest_dir"
            
            # Copy recent log files (last 7 days)
            find "$app_log_dir" -name "*.log" -type f -mtime -7 -exec cp {} "$dest_dir/" \;
            
            if [ "$(ls -A "$dest_dir" 2>/dev/null)" ]; then
                found_logs=true
                log_message "Application logs copied from: $app_log_dir"
            else
                rmdir "$dest_dir" 2>/dev/null
            fi
        fi
    done
    
    if [ "$found_logs" = true ]; then
        tar -czf "$backup_file" -C "$LOG_BACKUP_DIR" "$backup_name"
        rm -rf "$temp_dir"
        
        chmod 640 "$backup_file"
        chown $BACKUP_USER:$BACKUP_GROUP "$backup_file"
        
        log_message "Application log backup completed: $backup_file"
        echo "$backup_file"
        return 0
    else
        log_message "No application log files found"
        rm -rf "$temp_dir"
        return 1
    fi
}

# Function to backup system logs
backup_system_logs() {
    local timestamp=$(date +%Y%m%d_%H%M%S)
    local backup_name="system_logs_backup_${timestamp}"
    local backup_file="${LOG_BACKUP_DIR}/${backup_name}.tar.gz"
    
    log_message "Starting system log backup: $backup_name"
    
    local temp_dir="${LOG_BACKUP_DIR}/${backup_name}"
    mkdir -p "$temp_dir/system"
    
    # Backup critical system logs
    local system_logs=(
        "/var/log/syslog"
        "/var/log/messages"
        "/var/log/kern.log"
        "/var/log/auth.log"
        "/var/log/secure"
        "/var/log/boot.log"
        "/var/log/dmesg"
        "/var/log/journal"
    )
    
    local found_logs=false
    
    for log_file in "${system_logs[@]}"; do
        if [ -e "$log_file" ]; then
            cp "$log_file" "$temp_dir/system/" 2>/dev/null
            if [ $? -eq 0 ]; then
                found_logs=true
                log_message "System log copied: $log_file"
            fi
        fi
    done
    
    # Backup journal logs if available
    if command -v journalctl >/dev/null 2>&1; then
        mkdir -p "$temp_dir/journal"
        
        # Export journal logs for the last 7 days
        journalctl --since "7 days ago" --output=json > "$temp_dir/journal/systemd.json" 2>/dev/null
        
        if [ -s "$temp_dir/journal/systemd.json" ]; then
            found_logs=true
            log_message "Systemd journal logs exported"
        fi
    fi
    
    if [ "$found_logs" = true ]; then
        tar -czf "$backup_file" -C "$LOG_BACKUP_DIR" "$backup_name"
        rm -rf "$temp_dir"
        
        chmod 640 "$backup_file"
        chown $BACKUP_USER:$BACKUP_GROUP "$backup_file"
        
        log_message "System log backup completed: $backup_file"
        echo "$backup_file"
        return 0
    else
        log_message "No system log files found"
        rm -rf "$temp_dir"
        return 1
    fi
}

# Function to compress and rotate logs before backup
rotate_logs() {
    log_message "Rotating logs before backup"
    
    for log_dir in "${LOG_DIRS[@]}"; do
        if [ -d "$log_dir" ]; then
            # Compress uncompressed log files older than 1 day
            find "$log_dir" -name "*.log" -type f -mtime +1 -exec gzip {} \;
            
            # Remove compressed logs older than retention period
            find "$log_dir" -name "*.log.gz" -type f -mtime +${RETENTION_DAYS} -delete
        fi
    done
    
    log_message "Log rotation completed"
}

# Function to encrypt backup
encrypt_backup() {
    local file="$1"
    
    if [ "$ENCRYPTION" = "true" ] && [ -f "$KEY_FILE" ]; then
        local encrypted_file="${file}.enc"
        openssl enc -aes-256-cbc -salt -in "$file" -out "$encrypted_file" -pass file:"$KEY_FILE"
        
        if [ $? -eq 0 ]; then
            rm "$file"
            log_message "Log backup encrypted: $encrypted_file"
            echo "$encrypted_file"
            return 0
        else
            log_message "ERROR: Failed to encrypt log backup: $file"
            return 1
        fi
    fi
    
    echo "$file"
}

# Function to upload to S3
upload_to_s3() {
    local file="$1"
    
    if [ "$S3_ENABLED" = "true" ] && [ -n "$S3_BUCKET" ]; then
        local s3_path="s3://${S3_BUCKET}/logs/$(basename "$file")"
        
        if [ -n "$S3_ENDPOINT" ]; then
            aws --endpoint-url "$S3_ENDPOINT" s3 cp "$file" "$s3_path" --storage-class "$S3_STORAGE_CLASS"
        else
            aws s3 cp "$file" "$s3_path" --storage-class "$S3_STORAGE_CLASS"
        fi
        
        if [ $? -eq 0 ]; then
            log_message "Log backup uploaded to S3: $s3_path"
            return 0
        else
            log_message "ERROR: Failed to upload log backup to S3: $s3_path"
            return 1
        fi
    fi
    
    return 0
}

# Main backup function
main() {
    local backup_files=()
    local start_time=$(date +%s)
    local backup_type="${1:-all}"
    
    log_message "Starting ${backup_type} log backup on {{ ansible_hostname }}"
    
    # Check if log backup is enabled
    if [ "$LOG_BACKUP_ENABLED" != "true" ]; then
        log_message "Log backup is disabled"
        return 0
    fi
    
    # Create backup directories
    create_backup_dir "$LOG_BACKUP_DIR"
    
    # Rotate logs before backup
    rotate_logs
    
    # Run backups based on type
    case "$backup_type" in
        all)
            local general_logs=$(backup_logs)
            if [ $? -eq 0 ] && [ -n "$general_logs" ]; then
                backup_files+=("$general_logs")
            fi
            
            local app_logs=$(backup_app_logs)
            if [ $? -eq 0 ] && [ -n "$app_logs" ]; then
                backup_files+=("$app_logs")
            fi
            ;;
        system)
            local sys_logs=$(backup_system_logs)
            if [ $? -eq 0 ] && [ -n "$sys_logs" ]; then
                backup_files+=("$sys_logs")
            fi
            ;;
        application)
            local app_logs=$(backup_app_logs)
            if [ $? -eq 0 ] && [ -n "$app_logs" ]; then
                backup_files+=("$app_logs")
            fi
            ;;
        *)
            local general_logs=$(backup_logs)
            if [ $? -eq 0 ] && [ -n "$general_logs" ]; then
                backup_files+=("$general_logs")
            fi
            ;;
    esac
    
    # Process backup files
    local successful_uploads=0
    local failed_uploads=0
    
    for backup_file in "${backup_files[@]}"; do
        # Encrypt backup
        local processed_file=$(encrypt_backup "$backup_file")
        if [ $? -eq 0 ]; then
            # Upload to S3
            if upload_to_s3 "$processed_file"; then
                ((successful_uploads++))
            else
                ((failed_uploads++))
            fi
        else
            ((failed_uploads++))
        fi
    done
    
    # Calculate duration
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    local duration_min=$((duration / 60))
    local duration_sec=$((duration % 60))
    
    # Send notification
    local subject="Log Backup Report - {{ ansible_hostname }}"
    local message="Log ${backup_type} backup completed in ${duration_min}m ${duration_sec}s
Successful uploads: $successful_uploads
Failed uploads: $failed_uploads
Total files processed: ${#backup_files[@]}
Server: {{ ansible_hostname }}"
    
    send_notification "$subject" "$message"
    
    log_message "Log backup completed in ${duration_min}m ${duration_sec}s"
    
    return 0
}

# Create log directory
mkdir -p "$(dirname "$LOG_FILE")"

# Run main function
main "$@"
