#!/bin/bash
# Backup Monitoring Script
# Generated by Ansible for {{ ansible_hostname }}
# Environment: {{ ansible_environment }}
# Generated: {{ ansible_date_time }}

# Load configuration
source /etc/backup/backup-config.sh

# Function to log messages
log_message() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" >> "$LOG_FILE"
}

# Function to send email notification
send_notification() {
    local subject="$1"
    local message="$2"
    
    if [ "$EMAIL_ENABLED" = "true" ]; then
        echo "$message" | mail -s "$subject" -r "$EMAIL_FROM" "$EMAIL_TO"
        log_message "Notification sent: $subject"
    fi
}

# Function to check backup service status
check_backup_service() {
    local service_name="$1"
    
    if systemctl is-active --quiet "$service_name"; then
        log_message "✓ $service_name service is running"
        return 0
    else
        log_message "✗ $service_name service is not running"
        return 1
    fi
}

# Function to check backup directories
check_backup_directories() {
    local issues_found=false
    
    log_message "Checking backup directories"
    
    # Check main backup directory
    if [ ! -d "$BACKUP_DIR" ]; then
        log_message "ERROR: Main backup directory not found: $BACKUP_DIR"
        issues_found=true
    else
        local backup_usage=$(df "$BACKUP_DIR" | tail -1 | awk '{print $5}' | sed 's/%//')
        if [ "$backup_usage" -gt 90 ]; then
            log_message "WARNING: Backup directory usage high: ${backup_usage}%"
            issues_found=true
        fi
    fi
    
    # Check backup subdirectories
    local backup_dirs=(
        "$SYSTEM_BACKUP_DIR"
        "$DB_BACKUP_DIR"
        "$APP_BACKUP_DIR"
        "$LOG_BACKUP_DIR"
        "$CONFIG_BACKUP_DIR"
    )
    
    for dir in "${backup_dirs[@]}"; do
        if [ ! -d "$dir" ]; then
            log_message "ERROR: Backup directory not found: $dir"
            issues_found=true
        fi
    done
    
    if [ "$issues_found" = false ]; then
        log_message "✓ All backup directories accessible"
        return 0
    else
        return 1
    fi
}

# Function to check recent backup activity
check_recent_activity() {
    log_message "Checking recent backup activity"
    
    local current_time=$(date +%s)
    local hours_ago=$((current_time - 24 * 3600))  # 24 hours ago
    local recent_backups=0
    local failed_backups=0
    
    # Check backup logs for recent activity
    if [ -f "$LOG_FILE" ]; then
        recent_backups=$(find "$LOG_FILE" -mtime -1 -exec grep -c "completed" {} \; 2>/dev/null || echo 0)
        failed_backups=$(find "$LOG_FILE" -mtime -1 -exec grep -c "ERROR\|FAILED" {} \; 2>/dev/null || echo 0)
    fi
    
    # Check backup files
    local recent_files=$(find "$BACKUP_DIR" -name "*.tar.gz" -o -name "*.sql.gz" -o -name "*.enc" -mtime -1 2>/dev/null | wc -l)
    
    log_message "Recent backup status: $recent_files backup files, $recent_backups successful log entries, $failed_backups failed log entries"
    
    if [ $recent_files -gt 0 ] || [ $recent_backups -gt 0 ]; then
        log_message "✓ Recent backup activity detected"
        return 0
    else
        log_message "WARNING: No recent backup activity detected (24 hours)"
        return 1
    fi
}

# Function to check backup file integrity
check_backup_integrity() {
    log_message "Checking backup file integrity"
    
    local corrupted_files=0
    local total_files=0
    
    # Check recent backup files
    while IFS= read -r -d '' backup_file; do
        ((total_files++))
        
        case "$backup_file" in
            *.gz)
                if ! gzip -t "$backup_file" >/dev/null 2>&1; then
                    ((corrupted_files++))
                    log_message "ERROR: Corrupted gzip file: $backup_file"
                fi
                ;;
            *.tar.gz)
                if ! tar -tzf "$backup_file" >/dev/null 2>&1; then
                    ((corrupted_files++))
                    log_message "ERROR: Corrupted tar.gz file: $backup_file"
                fi
                ;;
            *.enc)
                # For encrypted files, just check if file exists and is readable
                if [ ! -r "$backup_file" ]; then
                    ((corrupted_files++))
                    log_message "ERROR: Unreadable encrypted file: $backup_file"
                fi
                ;;
        esac
    done < <(find "$BACKUP_DIR" -name "*.tar.gz" -o -name "*.sql.gz" -o -name "*.enc" -mtime -7 -print0 2>/dev/null)
    
    if [ $corrupted_files -eq 0 ]; then
        log_message "✓ All backup files integrity checked ($total_files files)"
        return 0
    else
        log_message "ERROR: $corrupted_files corrupted files found out of $total_files"
        return 1
    fi
}

# Function to check S3 connectivity
check_s3_connectivity() {
    log_message "Checking S3 connectivity"
    
    if [ -z "$S3_BUCKET" ]; then
        log_message "INFO: S3 not configured, skipping connectivity check"
        return 0
    fi
    
    # Test S3 access
    if [ -n "$S3_ENDPOINT" ]; then
        aws --endpoint-url "$S3_ENDPOINT" s3 ls "s3://$S3_BUCKET/" --max-items 1 >/dev/null 2>&1
    else
        aws s3 ls "s3://$S3_BUCKET/" --max-items 1 >/dev/null 2>&1
    fi
    
    if [ $? -eq 0 ]; then
        log_message "✓ S3 connectivity verified"
        return 0
    else
        log_message "ERROR: S3 connectivity failed"
        return 1
    fi
}

# Function to check backup schedule
check_backup_schedule() {
    log_message "Checking backup schedules"
    
    local schedule_issues=false
    
    # Check cron jobs
    local cron_jobs=$(crontab -l 2>/dev/null | grep -v "^#" | grep -v "^$")
    
    if [ -n "$cron_jobs" ]; then
        log_message "Current backup cron jobs:"
        echo "$cron_jobs" | while read -r line; do
            log_message "  $line"
        done
    else
        log_message "WARNING: No backup cron jobs found"
        schedule_issues=true
    fi
    
    # Check systemd timers (if available)
    if command -v systemctl >/dev/null 2>&1; then
        local backup_timers=$(systemctl list-timers --all | grep backup)
        
        if [ -n "$backup_timers" ]; then
            log_message "Systemd backup timers:"
            log_message "$backup_timers"
        fi
    fi
    
    if [ "$schedule_issues" = false ]; then
        log_message "✓ Backup schedules configured"
        return 0
    else
        return 1
    fi
}

# Function to check disk space
check_disk_space() {
    log_message "Checking disk space availability"
    
    local space_issues=false
    local backup_dirs=(
        "$BACKUP_DIR"
        "$SYSTEM_BACKUP_DIR"
        "$DB_BACKUP_DIR"
        "$APP_BACKUP_DIR"
        "$LOG_BACKUP_DIR"
        "$CONFIG_BACKUP_DIR"
    )
    
    for dir in "${backup_dirs[@]}"; do
        if [ -d "$dir" ]; then
            local disk_usage=$(df "$dir" | tail -1 | awk '{print $5}' | sed 's/%//')
            local available_space=$(df -h "$dir" | tail -1 | awk '{print $4}')
            
            if [ "$disk_usage" -gt 85 ]; then
                log_message "WARNING: High disk usage for $dir: ${disk_usage}% (${available_space} available)"
                space_issues=true
            elif [ "$disk_usage" -gt 90 ]; then
                log_message "ERROR: Critical disk usage for $dir: ${disk_usage}% (${available_space} available)"
                space_issues=true
            else
                log_message "✓ Disk usage OK for $dir: ${disk_usage}% (${available_space} available)"
            fi
        fi
    done
    
    if [ "$space_issues" = false ]; then
        return 0
    else
        return 1
    fi
}

# Function to check backup processes
check_backup_processes() {
    log_message "Checking backup processes"
    
    local running_processes=0
    
    # Check for running backup processes
    running_processes=$(ps aux | grep -E "(backup|rsync|tar\.gz)" | grep -v grep | wc -l)
    
    if [ $running_processes -gt 0 ]; then
        log_message "INFO: $running_processes backup processes currently running"
        ps aux | grep -E "(backup|rsync|tar\.gz)" | grep -v grep | while read -r line; do
            log_message "  $line"
        done
    else
        log_message "INFO: No backup processes currently running"
    fi
    
    # Check for stuck processes (running > 4 hours)
    local stuck_processes=$(ps aux | grep -E "(backup|rsync)" | grep -v grep | awk '$9 ~ /^[0-9]/ && ($9 * 1) > 14400' | wc -l)
    
    if [ $stuck_processes -gt 0 ]; then
        log_message "WARNING: $stuck_processes potentially stuck backup processes detected"
        return 1
    else
        log_message "✓ No stuck backup processes detected"
        return 0
    fi
}

# Function to generate monitoring report
generate_monitoring_report() {
    local overall_status="$1"
    local issues_count="$2"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    cat << EOF
Backup Monitoring Report
Generated: $timestamp
Server: {{ ansible_hostname }}

Overall Status: $overall_status
Issues Found: $issues_count

Monitoring Checks:
- Service Status: $(systemctl is-active backup-cron 2>/dev/null || echo "Unknown")
- Directory Access: All backup directories checked
- Recent Activity: Last 24 hours of backup activity
- File Integrity: Recent backup files verified
- S3 Connectivity: S3 bucket access tested
- Backup Schedule: Cron jobs and systemd timers checked
- Disk Space: Backup directories storage checked
- Process Status: Running backup processes monitored

System Information:
- Hostname: {{ ansible_hostname }}
- OS: {{ ansible_distribution }} {{ ansible_distribution_version }}
- Uptime: $(uptime -p 2>/dev/null | head -1 || uptime)
- Load Average: $(uptime | awk -F'load average:' '{print $2}')
- Memory Usage: $(free -h | grep Mem | awk '{print $3 "/" $2}')
- Disk Usage: $(df -h "$BACKUP_DIR" | tail -1)

Recommendations:
EOF

    if [ $issues_count -gt 0 ]; then
        cat << EOF
- Address identified issues immediately
- Review backup logs for detailed error information
- Verify backup schedules and dependencies
- Consider implementing additional monitoring and alerting
- Check system resources (disk space, memory, CPU)
- Review S3 configuration and credentials
EOF
    else
        cat << EOF
- Continue regular monitoring of backup systems
- Periodically test backup restoration procedures
- Review backup retention policies
- Monitor backup performance and trends
- Keep backup software and dependencies updated
EOF
    fi
}

# Main monitoring function
main() {
    local start_time=$(date +%s)
    local issues_count=0
    local overall_status="HEALTHY"
    
    log_message "Starting backup monitoring on {{ ansible_hostname }}"
    
    # Run all monitoring checks
    if ! check_backup_directories; then
        ((issues_count++))
        overall_status="WARNING"
    fi
    
    if ! check_recent_activity; then
        ((issues_count++))
        overall_status="WARNING"
    fi
    
    if ! check_backup_integrity; then
        ((issues_count++))
        overall_status="CRITICAL"
    fi
    
    if ! check_s3_connectivity; then
        ((issues_count++))
        overall_status="CRITICAL"
    fi
    
    if ! check_backup_schedule; then
        ((issues_count++))
        overall_status="WARNING"
    fi
    
    if ! check_disk_space; then
        ((issues_count++))
    fi
    
    if ! check_backup_processes; then
        ((issues_count++))
        overall_status="WARNING"
    fi
    
    # Calculate duration
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    local duration_min=$((duration / 60))
    local duration_sec=$((duration % 60))
    
    # Generate and log report
    local report=$(generate_monitoring_report "$overall_status" "$issues_count")
    echo "$report" >> "$LOG_FILE"
    
    log_message "Backup monitoring completed in ${duration_min}m ${duration_sec}s - Status: $overall_status, Issues: $issues_count"
    
    # Send notification if issues found
    if [ $issues_count -gt 0 ]; then
        local subject="Backup Monitoring Alert - {{ ansible_hostname }}"
        local message="Backup monitoring detected $issues_count issues on {{ ansible_hostname }}
Overall Status: $overall_status

$report"
        
        send_notification "$subject" "$message"
    fi
    
    return $issues_count
}

# Create log directory
mkdir -p "$(dirname "$LOG_FILE")"

# Run main function
main "$@"
